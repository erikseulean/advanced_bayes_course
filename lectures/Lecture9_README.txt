In this lecture we will first discuss Bayesian inference for the
normal distribution (Section 1.9). We review the cases where Mu is
known or Sigma^2 is known and then we will see that, when both mu and sigma^2
are unknown, we need a new version of the Bayes theorem (Section 1.8) for
the multi-parameter case. Finally, we will start discussing the difficulties
arising from the multi-parameter case and introduce an important idea
to overcome them (Section 1.10).

There are no slides for this lecture but I will
follow Sections 1.8 to 1.10 of the Lecture notes
in the order mentioned above.